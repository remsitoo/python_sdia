{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Practical session 4 - K-nearest neighbours (K-NN) classification with numpy, scikit-learn, cython and numba\n",
    "\n",
    "Students (pair):\n",
    "- [Student 1]([link](https://github.com/username1))\n",
    "- [Student 2]([link](https://github.com/username2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Useful references for this lab**:\n",
    "\n",
    "[1] scikit-learn: [documentation](https://scikit-learn.org/stable/modules/neighbors.html?highlight=knn%20classification)\n",
    "\n",
    "[2] `numba`: [documentation](http://numba.pydata.org/) \n",
    "\n",
    "[3] cython: [a very useful tutorial](https://cython.readthedocs.io/en/latest/src/userguide/numpy_tutorial.html#numpy-tutorial), and [another one](http://docs.cython.org/en/latest/src/tutorial/cython_tutorial.html)\n",
    "\n",
    "\n",
    "\n",
    "## <a name=\"content\">Contents</a>\n",
    "- [Exercise 1: KNN classification with numpy and sklearn](#ex1)\n",
    "- [Exercise 2: Code acceleration with cython](#ex2)\n",
    "- [Exercise 3: Code acceleration with numba](#ex3)\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <a name=\"ex1\">Exercise 1: K-Nearest Neighbours (K-NN) classification with numpy and scikit-learn</a> [(&#8593;)](#content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This session is a first introduction to classification using the most intuitive non parametric method: the $K$-nearest neighbours. The principle is [the following](https://scikit-learn.org/stable/modules/neighbors.html?highlight=knn%20classification). A set of labelled observations is given as a learning set. A classification taks then consists in assigning a label to any new observation. In particular, the K-NN approach consists in assigning to the observation the most frequent label among its $K$ nearest neighbours taken in the training set."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A. Validation on synthetic data\n",
    "\n",
    "Load the training and test datasets `data/synth_train.txt` and `data/synth_test.txt`. Targets belong to the set $\\{1,2\\}$ and entries belong to $\\mathbb{R}^2$. The file `data/synth_train.txt` contain 100 training data samples, and `data/synth_test.txt` contains 200 test samples, where:\n",
    "\n",
    "- the 1st column contains the label of the class the sample;\n",
    "- columns 2 & 3 contain the coordinates of each sample (in $\\mathbb{R}^2$).\n",
    "\n",
    "Useful commands can be found below."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "# load the training set\n",
    "train = np.loadtxt('data/synth_train.txt')  #...,delimiter=',') if there are ',' as delimiters\n",
    "class_train = train[:,0]\n",
    "x_train = train[:,1:]\n",
    "N_train = train.shape[0]\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "# load the test set\n",
    "test = np.loadtxt('/datasynth_test.txt') \n",
    "class_test_1 = test[test[:,0]==1]\n",
    "class_test_2 = test[test[:,0]==2]\n",
    "x_test = test[:,1:]\n",
    "N_test = test.shape[0]\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1\\. Display the training set and distinguish the two classes. \n",
    "\n",
    "> Hint: useful functions include `matplotlib.pyplot.scatter` or `matplotlib.pyplot.plot`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Answer:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2\\. Implement the K-nearest neighbours algorithm for classification.\n",
    "\n",
    "> Hint: \n",
    "> - useful functions include `numpy.linalg.norm`, `numpy.argsort`, `numpy.bincount`;\n",
    "> - implement the algorithm as a function rather than an object. This will drastically simplify the acceleration step using Cython.\n",
    "> - for an optimized partial sorting procedure, you may have a look at the [`bottleneck.argpartition` function](https://bottleneck.readthedocs.io/en/latest/reference.html#bottleneck.argpartition).\n",
    "> 1. Compute for each row in `x_test` (if necessary use `np.newaxis`) its distance with respect to `x_train`:\n",
    ">  - Use  `numpy.linalg.norm` (in which dimension this distance is computed ? Consider using `axis` argument)\n",
    "> 2. Sort the ordered collection of distances (indices from smallest to largest (in ascending order) by the distances):\n",
    ">   - Use `np.argsort` (at the end replace this procedure by `bottleneck.argpartition`)\n",
    ">   - Once the sorting is done, we take only the indices of `labels` of the `n_neighbours` nearest neighbours of the `class_train` :\n",
    ">     - `id = np.argsort(distances)[:n_ neighbours]` and `labels = class_train[id]`\n",
    "> 3. The K-nearest can be used for **Regression**, in this case it is necessary to return the mean of the K-labels. For **Classification**,  we return the mode of the K-labels :\n",
    "> - Use `np.bincount` for `labels` to affect the variable `class_pred[q]` (for row `q`). This procedure counts the number of occurrences of each value in array. **Mode** is the value that appears. How can we get this value ?\n",
    "\n",
    "\n",
    "```python\n",
    "import numpy as np\n",
    "import bottleneck as bn\n",
    "\n",
    "# Create a random array\n",
    "arr = np.random.rand(10)\n",
    "N = 3  # Number of smallest elements to retrieve\n",
    "\n",
    "# Using np.argsort() to get indices of the first N elements\n",
    "sorted_indices = np.argsort(arr)[:N]\n",
    "\n",
    "# Using bottleneck.argpartition() to get the first N smallest indices\n",
    "partitioned_indices = bn.argpartition(arr, N)[:N]\n",
    "\n",
    "# Display the results\n",
    "print(\"Original array:\", arr)\n",
    "print(\"Indices using np.argsort:\", sorted_indices)\n",
    "print(\"First N elements using np.argsort:\", arr[sorted_indices])\n",
    "\n",
    "print(\"Indices using bottleneck.argpartition:\", partitioned_indices)\n",
    "print(\"First N elements using bottleneck.argpartition:\", arr[partitioned_indices])\n",
    "\n",
    "are_equal = set(arr[sorted_indices]) == set(arr[partitioned_indices])\n",
    "print(are_equal)\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Answer:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3\\. Compute the error rate on the training set and the test set for $K \\in \\{1,2, \\dotsc, 20\\}$. Display the classification result (see 1.) for the configuration with the lowest error rate."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Answer:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4\\. Comment on your results. Which value of $K$ seems optimal ?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Answer:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5\\. Compare the results of you implementation with those of [`sklearn.neighbors.KNeighborsClassifier`](https://scikit-learn.org/stable/modules/generated/sklearn.neighbors.KNeighborsClassifier.html?highlight=kneighborsclassifier#sklearn.neighbors.KNeighborsClassifier). Compare the runtime of these two versions using the [`timeit`](https://docs.python.org/3/library/timeit.html) module (see session 1)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Answer:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### B. Application to a real dataset (Breast cancer Wisconsin).\n",
    "\n",
    "6\\. Apply the K-NN classifier to the real dataset `data/wdbc12.data.txt.` Further details about the data are provided in `data/wdbc12.names.txt`.\n",
    "\n",
    "> Hint: you can use the function [`train_test_split` from `sklearn.model_selection`](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.train_test_split.html) to split the dataset into a training and a test set."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Answer:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <a name=\"ex2\">Exercise 2: Code acceleration with cython</a> [(&#8593;)](#content)\n",
    "\n",
    "Cython allows C code to be easily interfaced with Python. It can be useful to make your code faster for a small coding effort, in particular when using loops. A general approach to optimize your code is outlined in the [Scipy lecture notes, Section 2.4](https://scipy-lectures.org/advanced/optimizing/index.html). Complementary reading about interfacing Python with C can be found in [Section 2.8](https://scipy-lectures.org/advanced/interfacing_with_c/interfacing_with_c.html).\n",
    "\n",
    "1\\. Read carefully the [cython tutorial](http://docs.cython.org/en/latest/src/tutorial/cython_tutorial.html), which describes step by the step how the toy example reported below has been developed."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Setup**: Compile the toy example provided in `example_cy/` by running, in the command line (anaconda prompt on windows)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```bash\n",
    "cd example_cy && python setup.py build_ext --inplace\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that the compilation process has been slightly automatised with the instructions reported in `example_cy/setup.py`. To test the module, run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!cd example_cy && python setup.py build_ext --inplace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import example_cy.example_cy.helloworld as toy\n",
    "\n",
    "toy.printhello()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "which should display\n",
    "```python\n",
    "Hello World\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Warning: \n",
    "> - do not forget to include an empty `__init__.py` file in the directory where your source code lives (`import` will fail if this is not the case).\n",
    "> - in case you have any setup issue, take a look at the `notes.md` file.\n",
    "> - if the C code and/or the executable do not seem to be regenerated by the build instructions, delete the C code and the executable first, and re-execute the compilation afterwards.\n",
    "> - do not hesitate to restart the Python kernel if necessary when the Cython executable has been re-generated."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2\\. Read the [Numpy/Cython tutorial](https://cython.readthedocs.io/en/latest/src/userguide/numpy_tutorial.html#numpy-tutorial), focussing on the paragraphs **Cython at a glance**, and **Your Cython environment** until **\"More generic code\"**. An example to compile a `.pyx` file depending on `numpy` is included in `example_np_cy/`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Remarks: \n",
    "> - the `annotate=True` flag in the `setup.py` allows an additional `.html` document to be generated (`<your_module_name>.html`), showing, for each line of the Cython code, the associated C instructions generated. Highlighted in yellow are the interactions with Python: the darker a region appears, the less efficient the generated C code is for this section. Work in priority on these! \n",
    "> - make sure all the previously generated files are deleted to allow the .html report to be generated;\n",
    "> - if you are working on your own machine and don't have a C/C++ compiler installed, read the notes provided in `notes.md`;\n",
    "> - use `cdef` for pure C functions (not exported to Python), `cpdef` should be favored for functions containing C instructions and later called from Python."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Answer:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3\\. Use Cython to implement a faster version of the numpy K-NN classifier implemented in [Exercise 1](#ex1). To do so, apply step-by-step the techniques introduced in the [Numpy/Cython tutorial](https://cython.readthedocs.io/en/latest/src/userguide/numpy_tutorial.html#numpy-tutorial) (*i.e.*, compile and time your code after each step to report the evolution, keeping track of the different versions of the cython function).\n",
    "\n",
    "> Hint: if you keep numpy arrays, make sure you use memory views (see numpy/cython tutorial) to access the elements within it. Be extremely careful with the type of the input arrays (you may need to recast the format of the input elements before entering the function. The `numpy.asarray` function can prove useful).\n",
    "\n",
    "> **Detailed guidelines**: a few notes and *caveat* to help you re-writing your code in cython:\n",
    "> - try to reduce the number of calls to numpy instructions as much as possible;\n",
    "> - **you do not have to optimize everything**. For the KNN function above, most of the time is spent in computing euclidean distances: you can thus focus on optimizing tihs operations by explicitly writing a for loop, which will ensure a minimal interaction with numpy when generating the associated C code at compilation. Calls to other numpy functions can be kept as-is;\n",
    "> - if you need to create an array within the cython function, used np.zeros (**do NOT use python lists**), and use a memory view to access its content;\n",
    "> - specify the type for all variables and numpy arrays. Pay attention to the type of the input arrays passed to the Cython function;\n",
    "> - whenever an array is returned, use memory views and index(es) to efficiently access its content;\n",
    "> - some numpy operators (e.g., broadcasting mechanism) do not work with memory views. In this case, you can directly write for loop(s) to encode the operation of interest (the loops will be optimized out at compile time);\n",
    "> - only use at the final development stage the following cython optimization (not before, as they can crash the program without any help):\n",
    ">\n",
    ">```python\n",
    ">@cython.boundscheck(False)\n",
    ">@cython.wraparound(False)\n",
    ">```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Answer:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4\\. Compare the runtime of the two algorithms (using `timeit.timeit`), and conclude about the interest of using cython in this case."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Answer:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <a name=\"ex3\">Exercise 3: Code acceleration with numba</a> [(&#8593;)](#content)\n",
    "\n",
    "`numba` is a just-in-time (JIT) compiler which translates Python codes into efficient machine code at runtime. A significant acceleration can be obtained by adding a few simple decorators to a standard Python function, up to a few restrictions detailed [here](http://numba.pydata.org/numba-doc/latest/user/performance-tips.html).\n",
    "\n",
    "If you have written most of the KNN classifier of exercise 1 with numpy, there is little to no chance that you will get an acceleration with numba (justifying the use of cython in this case). An interesting acceleration factor can however be obtained for the computation of the total variation investigated in session 2."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1\\. Take a look at the [numba 5 min tour](http://numba.pydata.org/numba-doc/latest/user/5minguide.html), and accelerate the total variation code from session 2 with the `@jit` decorator. You may have to rewrite small portions of your code to get the expected acceleration (see [performance tips](http://numba.pydata.org/numba-doc/latest/user/performance-tips.html))."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Answer:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2\\. Compare the runtime of the your numpy implementation and the `numba`-accelerated version (using `timeit.timeit`). \n",
    "> **Warning**: first run the numba version once to trigger the compilation, and then time it as usual. This is needed to avoid including the JIT compilation step in the runtime."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Answer:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code"
   ]
  }
 ],
 "metadata": {
  "file_extension": ".py",
  "kernelspec": {
   "display_name": "Python 3.8.10 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "mimetype": "text/x-python",
  "name": "python",
  "npconvert_exporter": "python",
  "pygments_lexer": "ipython3",
  "version": 3,
  "vscode": {
   "interpreter": {
    "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
